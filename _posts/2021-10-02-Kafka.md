# 【Note】Kafaka

Note for Kafka videos by confluent, which provides great help.
[Link][https://www.youtube.com/watch?v=jY02MB-sz8I&list=RDCMUCmZz-Gj3caLLzEWBtbYUXaA&index=3]

## 为什么需要消息中间件？

事件驱动的程序越来越多，从以前的静态到如今不断的事件流，对于一个程序需要处理的事情更加多了，更追求实时性，需要一个中间件有一下特点

1. Single platform to connect every one to every event
2. Real-time stream of events
3. All events stored fro historical view

![Kafka Element](https://typora-1302119905.cos.ap-nanjing.myqcloud.com/Coding/Kafka.png)

## 使用场景



## 概念



## 设计思路



## Kafka connector概念





## Element

**Producers**: The application which generate data and push(write) into the kafka cluster
**Kafka cluster**: The place store data, it contains many brokers
**Consumers**: The applicatin which poll(read) data from the Kafka cluster
**Zookeeper**: Used for cluster management, failure detection & recovery, basically all the distrubuted stuff.

*Producers and consumers are total decoupling.*

![Kafka Element](https://typora-1302119905.cos.ap-nanjing.myqcloud.com/Coding/%E6%88%AA%E5%B1%8F2021-10-01%20%E4%B8%8B%E5%8D%885.49.32.png)

**Topic**: It's like categories used to organize message. Producers write to topic and consumer read from topic. Topic 就是数据主题，是数据记录发布的地方,可以用来区分业务系统。[Linkd](https://kafka.apachecn.org/intro.html)
**Partition**: Topic are partitioned across multiple nodes physically, and the node here is partition, each node is in different broker.
**Broker**: 

1. Broken handles many partitions
2. Partition stored on Broker's disk
3. Partition is log file, append only
4. Broker replication: for a partition in broker A, that it would have a copy of it in other broker. So there would be a leader partition and a follower partition. Follower partition need to make sure update from the leader partition as quickly as possible.

*Why we need partition?*

1. Scalable
2. Replication

*How do we know which partition the message go to when writing as a producer?*

1. Depends on Kafka, Kafka use round robin method to decide which partition the message go to.
2. When writing a message, passing a key to Kafka, Kafka would use `hash(key) % number_of_partitions` to decide which partition to write into.
3. Customise by user

*When we need to method 2 above?*
When the user want some kind of message to by ordered, and the order of event is important, then just give those message a same key. By using method 2, all those data would go to one partition. And In the partition, it could make sure that those message is ordered by writing time.

## How Kafka works

#### **Partition leadership & Replication**

The producers and customers are always '*communicate*' with the leader of each partition

If one of the broker dies, for example broker 4, a new leader for partition 4 would be elected right away, can continue the writing and reading for this partition

![Partition Leader & Replication](https://typora-1302119905.cos.ap-nanjing.myqcloud.com/Coding/Partition-Leadership.png)

#### **Data retention policy**

The duration a partition store the data is configuable, by default it would be kept for a week. 
When the newest message in the segment is older than the retention period, then it would be a expired segment and deleted in the partition. 

#### **Producer Design**

![Produce-Design](https://typora-1302119905.cos.ap-nanjing.myqcloud.com/Coding/Producer-Design.png)

For each producer record, it would be serialised first and then the partitioner would decide which partition this message should go to. 

If the key in the record, then it would use round-robin to decide what to go defaultly, otherwise use function `hash(key) % number_of_partitions`  to decide which partition to put in the message

#### **Producer Guarantees**

 ![Producer-Guarantees](https://typora-1302119905.cos.ap-nanjing.myqcloud.com/Coding/producer-guarantees.png)

There is three types of level to guarantees the writing of the message

1. Do not wait any ACK for any broker, just send the message and then send the next one directly.

   Data Losing: ⭐️⭐️⭐️⭐️
   Latency: ⭐️

2. Wait the ACK from the leader, the leader would send the ACK after it writing the message into the disk

   Data Losing: ⭐️⭐️
   Latency: ⭐️⭐️⭐️

3. Wait the ACK from the leader and the all followers

   Data Losing: ⭐️
   Latency: ⭐️⭐️⭐️⭐️⭐️

#### **Customer Rebalances**

![Customer-Rebalances](https://typora-1302119905.cos.ap-nanjing.myqcloud.com/Coding/Customer-Rebalance.png)

#### **Compacted Topics**

When the consumer only want to know the lastest log message for a key(It measn for each message, it need to have a kep). The log only keep the newest value of a key

Compacted topic 适用于当消费者只关注每个key最新的那个消息，其他之前的消息并不关心时，使用compacted topic后，Kafka会定期将重复key的‘旧’消息删除，并且消费时提供最新的消息

## 生产端(Producer)

1. [应答机制](#Producer Guarantees)

